# ワクチンの副反応疑いに関する資料の csv 化

## URL

https://github.com/sarkov28/c19_mhlw_after_vaccination

## Features

厚生科学審議会 (予防接種・ワクチン分科会 副反応検討部会)  
https://www.mhlw.go.jp/stf/shingi/shingi-kousei_284075.html  
の、第66回会合、  
https://www.mhlw.go.jp/stf/shingi2/0000208910_00028.html  
の、2つの pdf、
- 資料１－１－２－１  
予防接種法に基づく医療機関からの副反応疑い報告状況について  
（コミナティ筋注・報告症例一覧）（PDF：9,868KB）  
- 資料１－１－２－２  
予防接種法に基づく医療機関からの副反応疑い報告状況について  
（COVID-19ワクチンモデルナ筋注・報告症例一覧）（PDF：550KB）

を csv にしてみました。  
表本体しか処理していないので、注の情報は含んでいません。  
注については、該当の pdf を参照して下さい。  

「細かいことはいいから1人1行の全部のデータを見たい」ということなら、  
3.5M ほどのデータになりますが、
2021-08-04_PfMo_t2.csv  
https://github.com/sarkov28/c19_mhlw_after_vaccination/raw/master/2021-08-04_PfMo_t2.csv  
がいいと思います。

## ファイル名の命名規則

yyyy-mm-dd_(製造会社)_(データフォーマット).csv
- yyyy-mm-dd は、会が開催された日付です。
- 製造会社は、現在のところ、以下です。
  - Pf: ファイザーのデータ
  - Mo: モデルナのデータ
  - PfMo: ファイザーとモデルナを統合したデータ  
  （統合方法については、後述）
- データフォーマットは、「データフォーマット」の項を参照して下さい。

最初からファイザーとモデルナを統合していないのは、厚生労働省のデータがファイザーとモデルナに分かれているからです。

## データフォーマット

文字コードは shift-jis（cp932）、改行コードは、CR+LF です。

この pdf には「1つの副反応に1行」の情報があります。  
このため、例えば「1人に2つの副反応」の情報がある時は、「1人の情報が2行」になっています。  
（例：モデルナ https://www.mhlw.go.jp/content/10601000/000816272.pdf の上から2つ目の No 9209 のデータ）  

該当するデータは、無数にあります。  
このタイプのデータをどう処理するかで、現在のところ、3つのフォーマットを用意してあります。  
- t1 形式: python + camelot によって csv 化したデータを、文字コードだけ変換したもの。  
1人1行のデータ。  
pdf における1つの枠の中の複数項目は、CR で区切られた文字列になっている。
（変換処理の参考 url: https://qiita.com/barobaro/items/f8c102d07144ca747099）  
表中に制御コード CR が混じっているのが欠点ですが、もとの状態を復元するには適しているかも知れない。
- t2 形式: t1 形式のデータの CR を、半角ブランクに置き換えたもの。  
今回変換した pdf には、置き換え前には半角ブランクは無かったが、今後については分からない。
- t3 形式: t1 形式のデータを、上掲の No 9209 のデータであれば、2行に分割したもの。1副反応1行となっている。

## 製造会社毎のデータの統合方法

製造会社毎に作成した t1、t2、t3 のファイルを、それぞれ統合しました。  
統合に際しては、linux コマンドの sort を以下のオプションで実行しました。  

sort --general-numeric-sort --stable (統合元のファイル名のリスト) > (統合結果のファイル名)  

ただし、このまま実行すると表頭が重複するので、tail -(統合結果のファイルの行数) で表頭を削除しました。  
(統合結果のファイルの行数) = (統合結果のデータ行数の合計値) + 1  
です。（1 は、表頭を1行入れるための調整。）  

統合結果は、左端の「No」のカラムの値の順になっています。  
「No」のカラムは、ほとんど全てのデータで整数なので問題ないのですが、今回の 2021-08-04 のデータにおいては、例外の項目が1つありました。
No = 15312 のデータのこのカラムは、「15312※2」となっています。  
今後において、こうした問題のために、統合の処理が困難になる可能性があります。

## Detail

私は、こちら  
https://github.com/sarkov28/c19_tokyo_kunishihyou
でも pdf の csv 化の作業をしています。  
c19_tokyo_kunishihyou では、python + tabula で行なっています。  
今回は、python + camelot で行いました。  

今回の pdf を python + tabula で処理しようとしたところ、2021-08-04 のファイザーのデータの 82 ページでエラーとなり、処理できませんでした。  
python + camelot では、正常に処理できました。  
（変換処理の参考 url: https://qiita.com/barobaro/items/f8c102d07144ca747099）  

## Plan

同様の情報が更新された場合には、対応したデータを作成し、ここに置く予定です。  
ただし、すぐに作業できるとは限りません。  

## Author

https://twitter.com/sarkov28

twitter やブログに、コロナに関することを色々と書いています。

- 新型コロナ関連の主な事柄のリスト  
  https://sarkov28.hatenablog.com/entry/2021/01/25/193020
- 新型コロナ関連の主な事柄のリスト（特に重要な項目）  
  https://sarkov28.hatenablog.com/entry/2021/01/25/193753

## License

このリポジトリにあるデータは、厚生労働省がこちら  
https://www.mhlw.go.jp/stf/shingi/shingi-kousei_284075.html  
以下で公表しているデータを加工したものです。  
自由に使っていただいて構いませんが、内容は保証出来ません。  
